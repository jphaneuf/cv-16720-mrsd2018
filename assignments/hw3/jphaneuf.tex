\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage{float}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
%\usepackage[toc,page]{appendix}
\graphicspath{ {./img/} }
\newcommand{\rpm}{\raisebox{.2ex}{$\scriptstyle\pm$}} 
\usepackage{listings}
\usepackage{xcolor}
\usepackage{indentfirst}
\usepackage{caption}
\usepackage[final]{pdfpages}


\begin{document}

\title{Joe Phaneuf \\ Computer Vision 16-720 Spring 2018 Homework 3 \\ Mar. 7, 2018 }
\date{}
\author{}
\maketitle

\newpage


%\stepcounter{section}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Q1}
\subsection{Q1.1}
In training deep networks, a ReLU activation can be chosen over a sigmoid as it is easily differentiable, and does not suffer slow training due to saturation.

\subsection{Q1.2}
Consider a one layer network with weights $W^{1}$ , bias $b^{1}$ , input $X$ and activation function $g$. The output of this network is 
$$
out^{1} = g( W^{1} X + b^{1} )
$$
if g is a linear operator function, then there will be some modified weights and biases such that
$$
out^{1} = \hat{W}^{1} X + \hat{b}^{1}
$$

For a subsequent layer, the pre-activation is
$$
W^{2} ( \hat{W}^{1} X + \hat{b}^{1} ) + b^{2}
$$
Which, due to the properties of matrix multiplication, can be reduced to some modified weights and biases
$$
\hat { W^{2} } X + \hat { b} ^{2}
$$

$\hat { W^{2} }$ and $\hat { b} ^{2}$ are of the same dimension as $W^{1}$ and $b^{1}$, meaning no additional discriminatory information can be encapsulated by the second layer. 

A non-linear activation function makes it impossible to combine weights as demonstrated above, meaning each additional layer does add to the discriminatory power of the network.

\section{Q2}
\subsection{Q2.1.1}
Weight initialization is an important factor for training neural networks. Naively initializing weights to zero results in zero valued gradients, which prevents weight updates. Initializing with all equal weights also reduces the same gradients for each weight, so training does not function properly. 

\subsection{Q2.1.3}
I chose to initialize weights from a uniform distribution ranging from -0.1 to 0.1. This was mostly from research and some experimention. Weights that are too large can create issues by way of massive gradients, weights that are too small can take a long time to train due to very small gradients.


\subsection{Q2.4.1}
Stochastic gradient descent is more robust to non-convex error manifolds , but may take longer to reach minima. Batch gradient descent will typically converge faster given error manifolds that are reasonably convex , but can be more expensive in terms of required RAM.

\subsection{Q3.1.1}
Figure \ref{fig:accloss} shows the training and validation accuracy and loss while training on the nmist26 dataset.
\begin{figure}[H]
\centering
\includegraphics[page=1,width=0.4\textwidth]{q311}
\caption{Training and validation accuracy and loss} 
\label{fig:accloss}
\end{figure}   

\subsection{Q3.1.2}
Figure \ref{fig:accloss} above shows accuracy and loss for a learning rate of 0.01.  Figure \ref{fig:accloss001} shows accuracy and loss for a learning rate of 0.001.
The higher learning rate of 0.01 performed better over 30 epochs, reaching a validation accuracy of 87 percent. versus the lower learning rate which achieved a validation accuracy of 73 percent. It is interesting to note that the accuracy and loss at the higher rate appear noisier. I suspect that too high of a learning rate could become problematic because of that.
\begin{figure}[H]
\centering
\includegraphics[page=1,width=0.4\textwidth]{q312}
\caption{Training and validation accuracy and loss} 
\label{fig:accloss001}
\end{figure}   

\subsection{Q3.1.3}
As reported in section Q3.1.1 , this neural network provided the best valiation accuracy over 30 epochs using a learning rate of 0.01. Applying this network to the nist26 test data set resulted in 88.5 percent accuracy and a average cross entropy loss of 0.5. Figure \ref{fig:weightviz} shows an image montage of weights in the first layer of this network. The first layer has 400 sets of 1024 length weight vectors.

Figure \ref{fig:initweightviz} shows the same montage with the weights initialized prior to training. The weights were initialized from a uniform distribution, and image appears to be white noise, which makes sense.

The learned weights clearly pick up on features that correspond to features of the training data set.
\begin{figure}[H]
\centering
\includegraphics[page=1,width=0.4\textwidth]{weight_montage}
\caption{Visual montage of first layer weights after training} 
\label{fig:weightviz}
\end{figure}   

\begin{figure}[H]
\centering
\includegraphics[page=1,width=0.4\textwidth]{init_weight_montage}
\caption{Visual montage of initial first layer weights } 
\label{fig:initweightviz}
\end{figure}   

\subsection{Q3.1.4}
Figure \ref{fig:initweightviz} shows a graphical confusion matrix for the nist26 test data. Correct predictions are shown in blue, incorrect predictions are shown in red. Each point is plotted with a low alpha, so darker points show higher frequency of occurence. This indicates that the most problematic classifications were predicting I for a true label of Z , and predicting an O for a true label of D. Honestly, I have trouble with that myself, so I can't be mad at my neural net on this one.

\begin{figure}[H]
\centering
\includegraphics[page=1,width=0.75\textwidth]{q314confusion}
\caption{ Confusion matrix for test data } 
\label{fig:initweightviz}
\end{figure}   


\end{document}
